{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.chat import Chat\n",
    "from app.models.UserInput import UserInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat()\n",
    "chat.init_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_id = \"abc\"\n",
    "chat.clear_chat(chat_id=chat_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"Suggests me some articles about water melon\"\n",
    "\n",
    "chat_id = \"abc\"\n",
    "user_input = UserInput(\n",
    "    chat_id=chat_id,\n",
    "    message=user_message,\n",
    "    currentGraph=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "1. Give \"Keyword node\"\n",
    "2. Give \"GrapLink from GraphData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIX HERE\n",
    "system_template_prompt = \"\"\"You are an AI assistance for encouraging the system to initialize new \"node\" from below data that was fetched from QdrantDB. Node have two types which are \"Paper\" and \"Keyword\".\n",
    "Keyword is a short word that related to topic, title or field of the input messages from user while \"Paper\" is the main content of articles in the database. Your tasks are generating \"Keyword\" node based on summarizing the content of user messages and \"Paper\" node, a node that contains more . Both of them follow this structure of node object: \n",
    "\n",
    "Don't forget to ensure that the values that will be assigned are related to data in the databas\n",
    "\n",
    "This is the guideines for you:\n",
    "1. Analyze the given user input to find some \"Keyword\" that related to the user message topic, papers, articles.\n",
    "2. From the paper that user give to you, You have to find the top most important 4-5 topics and keep their id, title, type, year, abstract (if the abstract too long just keep as long as you think it's important and meaningful),  author and source in Json format.\n",
    "3. After you have done the step 2, Create the nodes, this is the example structure. \n",
    "    \"links\" : [\n",
    "        \n",
    "            \"source\" : \"2410.18541_arxiv\",\n",
    "            \"target\" : \"2204.13154_arxiv\"\n",
    "        ,\n",
    "        \n",
    "            \"source\" : \"transformer-and-attention-is-all-you-need\",\n",
    "            \"target\" : \"2204.13154_arxiv\"\n",
    "        ,\n",
    "        \n",
    "            \"source\" : \"transformer-and-attention-is-all-you-need\",\n",
    "            \"target\" : \"2410.18541_arxiv\"\n",
    "        ,\n",
    "    ]\n",
    "\n",
    "\n",
    "Ensure that every pairs of the Graphlinks member are related and as you can see from the example, some graph link might have the same source, which store\n",
    "the ID of the starter node (the node that have higher level).\n",
    "Don't for get to change the id of source and target to the correct id of provided paper. The IDs in the examples isn't always the same as what users provide to you.\n",
    "However, You can adjust the inhertance of the graph using your decision to make it be more appropriate.\n",
    "4. Node with type \"keyword\" will have 3 fields [id], [type] and [title] (no label)\n",
    "5. In the end, Return them in json format by Nodes and GraphLinks is in the same level and re-check if everything is correct and follows the guidelines, IDs in GraphLinks are paired with the IDs from provided papers.\n",
    "6. Moreover, add one more section to the response Json, \"Summation\". It's a section to show the message that obtain from wraping the information up. You might add the title of the articles to make it be more easier to read. and don't for get to keep the conversation\n",
    "in friendly mood and always encourage the user to ask you if they have any problems or need any helps.\n",
    "Accordning to the amount, quality and usage of paper that related to the topic of the conversation. Do the user needs the more number of papers?\n",
    "If yes reply \"Yes\" Otherwise \"No\" followed by the reason of the answer. Furthermore, suggest the next appropriate step to the user by\n",
    "considering the overall of this conversation efficieintly. Be calm, friendly, natural and love to give the best service to the user.\n",
    "This is the structure:\n",
    "\"summation\" : [ \"msg\" : \"[the conclusion of analysis]\"],\n",
    "\n",
    "\"\"\"\n",
    "### FIX HERE\n",
    "\n",
    "chat.set_system_template_prompt(system_template_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Chat Template Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIX HERE\n",
    "chat_template_prompt = \"\"\"\n",
    "{paper_data}\n",
    "\"\"\"\n",
    "### FIX HERE\n",
    "\n",
    "chat.set_chat_template_prompt(chat_template_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### See the result of the chat\n",
    "\n",
    "initial_result = chat.test_initial_chat(user_input=user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat.clear_chat(chat_id=chat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.get_chat_history(chat_id=chat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from app.models.GraphData import GraphLink, Node, GraphData\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_chat_json_to_graph_link(chat_json_response: str) -> List[GraphLink]:\n",
    "    \"\"\"\n",
    "    Example of chat_json_response\n",
    "    ```json\n",
    "    [\n",
    "        {\n",
    "            \"source\": \"some_id\",\n",
    "            \"target\": \"some_id\",\n",
    "            \"index\": 0\n",
    "        }\n",
    "    ]\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    # Select content between ```json and ```\n",
    "    chat_json_response = chat_json_response.split(\"```json\")[1].split(\"```\")[0]\n",
    "    # print(chat_json_response)\n",
    "    graph_data = json.loads(chat_json_response)\n",
    "    # print(graph_data)\n",
    "    nodes_json = graph_data[\"nodes\"]\n",
    "    links_json = graph_data[\"links\"]\n",
    "\n",
    "    nodes = []\n",
    "    for node in nodes_json:\n",
    "        if \"label\" in node:\n",
    "            node[\"title\"] = node[\"label\"]\n",
    "            del node[\"label\"]\n",
    "        \n",
    "        if \"year\" not in node:\n",
    "            node[\"year\"] = None\n",
    "        \n",
    "        if \"abstract\" not in node:\n",
    "            node[\"abstract\"] = None\n",
    "\n",
    "        if \"authors\" not in node:\n",
    "            node[\"authors\"] = None\n",
    "\n",
    "        if \"source\" not in node:\n",
    "            node[\"source\"] = None\n",
    "            \n",
    "        node = Node(**node)\n",
    "        nodes.append(node)\n",
    "\n",
    "    links = []\n",
    "    for link in links_json:\n",
    "        link = GraphLink(**link)\n",
    "        links.append(link)\n",
    "\n",
    "    return GraphData(nodes=nodes, links=links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = format_chat_json_to_graph_link(initial_result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Detect Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_additional_message = \"I want to know more about Computer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_detect_additional_data = UserInput(\n",
    "    chat_id=chat_id,\n",
    "    message=detect_additional_message,\n",
    "    currentGraph=graph_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_additional_data_template = \"\"\"\n",
    "These are your informative data for making the decision if user needs more papers or not:\n",
    "- {message}\n",
    "- This is the current graph of information that user has:\n",
    "  {current_graph}\n",
    "\n",
    "These are your guidelines :\n",
    "\n",
    "Accordning to the amount, quality and usage of paper that related to the topic of the conversation. Do the user needs the more number of papers?\n",
    "If there are some papers in current graph that related to the topic that user's interted in of researching.\n",
    "If yes reply \"Yes\" Otherwise \"No\" followed by the reason of the answer. Furthermore, suggest the next appropriate step to the user by\n",
    "considering the overall of this conversation efficieintly. Be calm, friendly, natural and love to give the best service to the user.\n",
    "Return the response by this json template:\n",
    "\"isNeed\" : \"yes or no\",\n",
    "\"reason\" : \"the reason that you suggest user to find more papers or the reason that the papaers is enough for user\"\n",
    "\n",
    "\"\"\"\n",
    "chat.set_detect_additional_data_template(detect_additional_data_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_additional_data_result = chat.test_detect_additional_data(user_input=user_detect_additional_data)\n",
    "detect_additional_data_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_detect_additional_data_to_boolean(detect_additional_data_response: str) -> bool:\n",
    "#     return detect_additional_data_response.lower() == \"yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_detect_additional_data_to_boolean(detect_additional_data_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_chat_result = chat.test_continue_chat(user_input=user_detect_additional_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
