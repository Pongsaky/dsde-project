{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.chat import Chat\n",
    "from app.models.UserInput import UserInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gcpuppy/Documents/WorkSpace/DataSci/dsde-project/src/database/qdrant.py:37: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.df = pd.read_csv(\"combined_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "chat = Chat()\n",
    "chat.init_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_id = \"abc\"\n",
    "chat.clear_chat(chat_id=chat_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"Give me the papers that related to field of aerodynamic especially the military purposes\"\n",
    "\n",
    "user_input = UserInput(\n",
    "    chat_id=chat_id,\n",
    "    message=user_message,\n",
    "    currentGraph=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "1. Give \"Keyword node\"\n",
    "2. Give \"GrapLink from GraphData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIX HERE\n",
    "system_template_prompt = \"\"\"You are an AI assistance for encouraging the system to initialize new \"Node\" from below data that was fetched from QdrantDB. Node have two types which are \"Paper\" and \"Keyword\".\n",
    "Keyword is a short word that related to topic, title or field of the input messages from user while \"Paper\" is the main content of articles in the database. Your tasks are generating \"Keyword\" node based on summarizing the content of user messages and \"Paper\" node, a node that contains more . Both of them follow this structure of node object: \n",
    "export interface Node {\n",
    "title: string\n",
    "type: 'paper' | 'keyword'\n",
    "color?: string\n",
    "citations?: number\n",
    "year?: number\n",
    "abstract?: string\n",
    "authors?: string[]\n",
    "relevance?: number\n",
    "}\n",
    "export interface GraphLink {\n",
    "source: string\n",
    "target: string\n",
    "index?: number\n",
    "}\n",
    "Don't forget to ensure that the values that will be assigned are related to data in the databas\n",
    "This is the guideines for you:\n",
    "1. Analyze the given user input \"Keyword\".\n",
    "2. Create nodes based on related keywords.\n",
    "3. Give me the response in format of Json of GraphLink\n",
    "source is the ID of starting node,\n",
    "target is ID of destination node,\n",
    "\"\"\"\n",
    "### FIX HERE\n",
    "\n",
    "chat.set_system_template_prompt(system_template_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Chat Template Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIX HERE\n",
    "chat_template_prompt = \"\"\"\n",
    "Below is the GraphData that was fetched from QdrantDB. You can use this data to generate new \"Node\" based on the user message.\n",
    "{paper_data}\n",
    "\"\"\"\n",
    "### FIX HERE\n",
    "\n",
    "chat.set_chat_template_prompt(chat_template_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of {paper_data}\n",
    "====================================================================================================================================\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": \"2410.18541_arxiv\",\n",
    "    \"title\": \"On Explaining with Attention Matrices\",\n",
    "    \"type\": \"paper\",\n",
    "    \"year\": 2024,\n",
    "    \"abstract\": \"  This paper explores the much discussed, possible explanatory link between\\nattention weights (AW) in transformer models and predicted output. Contrary to\\nintuition and early research on attention, more recent prior research has\\nprovided formal arguments and empirical evidence that AW are not explanatorily\\nrelevant. We show that the formal arguments are incorrect. We introduce and\\neffectively compute efficient attention, which isolates the effective\\ncomponents of attention matrices in tasks and models in which AW play an\\nexplanatory role. We show that efficient attention has a causal role (provides\\nminimally necessary and sufficient conditions) for predicting model output in\\nNLP tasks requiring contextual information, and we show, contrary to [7], that\\nefficient attention matrices are probability distributions and are effectively\\ncalculable. Thus, they should play an important part in the explanation of\\nattention based model behavior. We offer empirical experiments in support of\\nour method illustrating various properties of efficient attention with various\\nmetrics on four datasets.\\n\",\n",
    "    \"authors\": [\n",
    "        \"Omar Naim and Nicholas Asher\"\n",
    "    ],\n",
    "    \"source\": \"arxiv\"\n",
    "}\n",
    "```\n",
    "\n",
    "==========================================================================================================\n",
    "```json\n",
    "{\n",
    "    \"id\": \"2204.13154_arxiv\",\n",
    "    \"title\": \"Attention Mechanism in Neural Networks: Where it Comes and Where it Goes\",\n",
    "    \"type\": \"paper\",\n",
    "    \"year\": 2022,\n",
    "    \"abstract\": \"  A long time ago in the machine learning literature, the idea of incorporating\\na mechanism inspired by the human visual system into neural networks was\\nintroduced. This idea is named the attention mechanism, and it has gone through\\na long development period. Today, many works have been devoted to this idea in\\na variety of tasks. Remarkable performance has recently been demonstrated. The\\ngoal of this paper is to provide an overview from the early work on searching\\nfor ways to implement attention idea with neural networks until the recent\\ntrends. This review emphasizes the important milestones during this progress\\nregarding different tasks. By this way, this study aims to provide a road map\\nfor researchers to explore the current development and get inspired for novel\\napproaches beyond the attention.\\n\",\n",
    "    \"authors\": [\n",
    "        \"Derya Soydaner\"\n",
    "    ],\n",
    "    \"source\": \"arxiv\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example output\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"GraphNodes\" : [\n",
    "        {\n",
    "            data : {\n",
    "                \"id\": \"2410.18541_arxiv\",\n",
    "                \"title\": \"On Explaining with Attention Matrices\",\n",
    "                \"type\": \"paper\",\n",
    "                \"year\": 2024,\n",
    "                \"abstract\": \"  This paper explores the much discussed, possible explanatory link between\\nattention weights (AW) in transformer models and predicted output. Contrary to\\nintuition and early research on attention, more recent prior research has\\nprovided formal arguments and empirical evidence that AW are not explanatorily\\nrelevant. We show that the formal arguments are incorrect. We introduce and\\neffectively compute efficient attention, which isolates the effective\\ncomponents of attention matrices in tasks and models in which AW play an\\nexplanatory role. We show that efficient attention has a causal role (provides\\nminimally necessary and sufficient conditions) for predicting model output in\\nNLP tasks requiring contextual information, and we show, contrary to [7], that\\nefficient attention matrices are probability distributions and are effectively\\ncalculable. Thus, they should play an important part in the explanation of\\nattention based model behavior. We offer empirical experiments in support of\\nour method illustrating various properties of efficient attention with various\\nmetrics on four datasets.\\n\",\n",
    "                \"authors\": [\n",
    "                    \"Omar Naim and Nicholas Asher\"\n",
    "                ],\n",
    "                \"source\": \"arxiv\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            data : {\n",
    "                \"id\": \"2204.13154_arxiv\",\n",
    "                \"title\": \"Attention Mechanism in Neural Networks: Where it Comes and Where it Goes\",\n",
    "                \"type\": \"paper\",\n",
    "                \"year\": 2022,\n",
    "                \"abstract\": \"  A long time ago in the machine learning literature, the idea of incorporating\\na mechanism inspired by the human visual system into neural networks was\\nintroduced. This idea is named the attention mechanism, and it has gone through\\na long development period. Today, many works have been devoted to this idea in\\na variety of tasks. Remarkable performance has recently been demonstrated. The\\ngoal of this paper is to provide an overview from the early work on searching\\nfor ways to implement attention idea with neural networks until the recent\\ntrends. This review emphasizes the important milestones during this progress\\nregarding different tasks. By this way, this study aims to provide a road map\\nfor researchers to explore the current development and get inspired for novel\\napproaches beyond the attention.\\n\",\n",
    "                \"authors\": [\n",
    "                    \"Derya Soydaner\"\n",
    "                ],\n",
    "                \"source\": \"arxiv\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            // Keyword Node added\n",
    "            data: {\n",
    "                \"id\" : \"transformer-and-attention-is-all-you-need\",\n",
    "                \"title\" : \"Transformer and Attention is all you need\",\n",
    "                \"type\" : \"keyword\",\n",
    "                \"abstract\" : \"\",\n",
    "                \"authors\" : \"\",\n",
    "                \"source\" : \"\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"GraphLinks\" : [\n",
    "        {\n",
    "            \"source\" : \"2410.18541_arxiv\",\n",
    "            \"target\" : \"2204.13154_arxiv\"\n",
    "        },\n",
    "        {\n",
    "            \"source\" : \"transformer-and-attention-is-all-you-need\",\n",
    "            \"target\" : \"2204.13154_arxiv\"\n",
    "        },\n",
    "        {\n",
    "            \"source\" : \"transformer-and-attention-is-all-you-need\",\n",
    "            \"target\" : \"2410.18541_arxiv\"\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "{\n",
      "    \"id\": \"2410.18541_arxiv\",\n",
      "    \"title\": \"On Explaining with Attention Matrices\",\n",
      "    \"type\": \"paper\",\n",
      "    \"year\": 2024,\n",
      "    \"abstract\": \"  This paper explores the much discussed, possible explanatory link between\\nattention weights (AW) in transformer models and predicted output. Contrary to\\nintuition and early research on attention, more recent prior research has\\nprovided formal arguments and empirical evidence that AW are not explanatorily\\nrelevant. We show that the formal arguments are incorrect. We introduce and\\neffectively compute efficient attention, which isolates the effective\\ncomponents of attention matrices in tasks and models in which AW play an\\nexplanatory role. We show that efficient attention has a causal role (provides\\nminimally necessary and sufficient conditions) for predicting model output in\\nNLP tasks requiring contextual information, and we show, contrary to [7], that\\nefficient attention matrices are probability distributions and are effectively\\ncalculable. Thus, they should play an important part in the explanation of\\nattention based model behavior. We offer empirical experiments in support of\\nour method illustrating various properties of efficient attention with various\\nmetrics on four datasets.\\n\",\n",
      "    \"authors\": [\n",
      "        \"Omar Naim and Nicholas Asher\"\n",
      "    ],\n",
      "    \"source\": \"arxiv\"\n",
      "}\n",
      "{\n",
      "    \"id\": \"2204.13154_arxiv\",\n",
      "    \"title\": \"Attention Mechanism in Neural Networks: Where it Comes and Where it Goes\",\n",
      "    \"type\": \"paper\",\n",
      "    \"year\": 2022,\n",
      "    \"abstract\": \"  A long time ago in the machine learning literature, the idea of incorporating\\na mechanism inspired by the human visual system into neural networks was\\nintroduced. This idea is named the attention mechanism, and it has gone through\\na long development period. Today, many works have been devoted to this idea in\\na variety of tasks. Remarkable performance has recently been demonstrated. The\\ngoal of this paper is to provide an overview from the early work on searching\\nfor ways to implement attention idea with neural networks until the recent\\ntrends. This review emphasizes the important milestones during this progress\\nregarding different tasks. By this way, this study aims to provide a road map\\nfor researchers to explore the current development and get inspired for novel\\napproaches beyond the attention.\\n\",\n",
      "    \"authors\": [\n",
      "        \"Derya Soydaner\"\n",
      "    ],\n",
      "    \"source\": \"arxiv\"\n",
      "}\n",
      "{\n",
      "    \"id\": \"1810.12427_arxiv\",\n",
      "    \"title\": \"Parallel Attention Mechanisms in Neural Machine Translation\",\n",
      "    \"type\": \"paper\",\n",
      "    \"year\": 2018,\n",
      "    \"abstract\": \"  Recent papers in neural machine translation have proposed the strict use of\\nattention mechanisms over previous standards such as recurrent and\\nconvolutional neural networks (RNNs and CNNs). We propose that by running\\ntraditionally stacked encoding branches from encoder-decoder attention- focused\\narchitectures in parallel, that even more sequential operations can be removed\\nfrom the model and thereby decrease training time. In particular, we modify the\\nrecently published attention-based architecture called Transformer by Google,\\nby replacing sequential attention modules with parallel ones, reducing the\\namount of training time and substantially improving BLEU scores at the same\\ntime. Experiments over the English to German and English to French translation\\ntasks show that our model establishes a new state of the art.\\n\",\n",
      "    \"authors\": [\n",
      "        \"Julian Richard Medina\",\n",
      "        \" Jugal Kalita\"\n",
      "    ],\n",
      "    \"source\": \"arxiv\"\n",
      "}\n",
      "{\n",
      "    \"id\": \"2305.07239_arxiv\",\n",
      "    \"title\": \"T-former: An Efficient Transformer for Image Inpainting\",\n",
      "    \"type\": \"paper\",\n",
      "    \"year\": 2023,\n",
      "    \"abstract\": \"  Benefiting from powerful convolutional neural networks (CNNs), learning-based\\nimage inpainting methods have made significant breakthroughs over the years.\\nHowever, some nature of CNNs (e.g. local prior, spatially shared parameters)\\nlimit the performance in the face of broken images with diverse and complex\\nforms. Recently, a class of attention-based network architectures, called\\ntransformer, has shown significant performance on natural language processing\\nfields and high-level vision tasks. Compared with CNNs, attention operators are\\nbetter at long-range modeling and have dynamic weights, but their computational\\ncomplexity is quadratic in spatial resolution, and thus less suitable for\\napplications involving higher resolution images, such as image inpainting. In\\nthis paper, we design a novel attention linearly related to the resolution\\naccording to Taylor expansion. And based on this attention, a network called\\n$T$-former is designed for image inpainting. Experiments on several benchmark\\ndatasets demonstrate that our proposed method achieves state-of-the-art\\naccuracy while maintaining a relatively low number of parameters and\\ncomputational complexity. The code can be found at\\n\\\\href{https://github.com/dengyecode/T-former_image_inpainting}{github.com/dengyecode/T-former\\\\_image\\\\_inpainting}\\n\",\n",
      "    \"authors\": [\n",
      "        \"Ye Deng\",\n",
      "        \" Siqi Hui\",\n",
      "        \" Sanping Zhou\",\n",
      "        \" Deyu Meng\",\n",
      "        \" Jinjun Wang\"\n",
      "    ],\n",
      "    \"source\": \"arxiv\"\n",
      "}\n",
      "{\n",
      "    \"id\": \"2203.14263_arxiv\",\n",
      "    \"title\": \"A General Survey on Attention Mechanisms in Deep Learning\",\n",
      "    \"type\": \"paper\",\n",
      "    \"year\": 2022,\n",
      "    \"abstract\": \"  Attention is an important mechanism that can be employed for a variety of\\ndeep learning models across many different domains and tasks. This survey\\nprovides an overview of the most important attention mechanisms proposed in the\\nliterature. The various attention mechanisms are explained by means of a\\nframework consisting of a general attention model, uniform notation, and a\\ncomprehensive taxonomy of attention mechanisms. Furthermore, the various\\nmeasures for evaluating attention models are reviewed, and methods to\\ncharacterize the structure of attention models based on the proposed framework\\nare discussed. Last, future work in the field of attention models is\\nconsidered.\\n\",\n",
      "    \"authors\": [\n",
      "        \"Gianni Brauwers and Flavius Frasincar\"\n",
      "    ],\n",
      "    \"source\": \"arxiv\"\n",
      "}\n",
      "{\n",
      "    \"id\": \"2302.07253_arxiv\",\n",
      "    \"title\": \"Energy Transformer\",\n",
      "    \"type\": \"paper\",\n",
      "    \"year\": 2023,\n",
      "    \"abstract\": \"  Our work combines aspects of three promising paradigms in machine learning,\\nnamely, attention mechanism, energy-based models, and associative memory.\\nAttention is the power-house driving modern deep learning successes, but it\\nlacks clear theoretical foundations. Energy-based models allow a principled\\napproach to discriminative and generative tasks, but the design of the energy\\nfunctional is not straightforward. At the same time, Dense Associative Memory\\nmodels or Modern Hopfield Networks have a well-established theoretical\\nfoundation, and allow an intuitive design of the energy function. We propose a\\nnovel architecture, called the Energy Transformer (or ET for short), that uses\\na sequence of attention layers that are purposely designed to minimize a\\nspecifically engineered energy function, which is responsible for representing\\nthe relationships between the tokens. In this work, we introduce the\\ntheoretical foundations of ET, explore its empirical capabilities using the\\nimage completion task, and obtain strong quantitative results on the graph\\nanomaly detection and graph classification tasks.\\n\",\n",
      "    \"authors\": [\n",
      "        \"Benjamin Hoover\",\n",
      "        \" Yuchen Liang\",\n",
      "        \" Bao Pham\",\n",
      "        \" Rameswar Panda\",\n",
      "        \" Hendrik\\n  Strobelt\",\n",
      "        \" Duen Horng Chau\",\n",
      "        \" Mohammed J. Zaki\",\n",
      "        \" Dmitry Krotov\"\n",
      "    ],\n",
      "    \"source\": \"arxiv\"\n",
      "}\n",
      "{\n",
      "    \"id\": \"1902.02181_arxiv\",\n",
      "    \"title\": \"Attention in Natural Language Processing\",\n",
      "    \"type\": \"paper\",\n",
      "    \"year\": 2021,\n",
      "    \"abstract\": \"  Attention is an increasingly popular mechanism used in a wide range of neural\\narchitectures. The mechanism itself has been realized in a variety of formats.\\nHowever, because of the fast-paced advances in this domain, a systematic\\noverview of attention is still missing. In this article, we define a unified\\nmodel for attention architectures in natural language processing, with a focus\\non those designed to work with vector representations of the textual data. We\\npropose a taxonomy of attention models according to four dimensions: the\\nrepresentation of the input, the compatibility function, the distribution\\nfunction, and the multiplicity of the input and/or output. We present the\\nexamples of how prior information can be exploited in attention models and\\ndiscuss ongoing research efforts and open challenges in the area, providing the\\nfirst extensive categorization of the vast body of literature in this exciting\\ndomain.\\n\",\n",
      "    \"authors\": [\n",
      "        \"Andrea Galassi\",\n",
      "        \" Marco Lippi\",\n",
      "        \" Paolo Torroni\"\n",
      "    ],\n",
      "    \"source\": \"arxiv\"\n",
      "}\n",
      "{\n",
      "    \"id\": \"2302.06015_arxiv\",\n",
      "    \"title\": \"A Theoretical Understanding of Shallow Vision Transformers: Learning,\\n  Generalization, and Sample Complexity\",\n",
      "    \"type\": \"paper\",\n",
      "    \"year\": 2023,\n",
      "    \"abstract\": \"  Vision Transformers (ViTs) with self-attention modules have recently achieved\\ngreat empirical success in many vision tasks. Due to non-convex interactions\\nacross layers, however, theoretical learning and generalization analysis is\\nmostly elusive. Based on a data model characterizing both label-relevant and\\nlabel-irrelevant tokens, this paper provides the first theoretical analysis of\\ntraining a shallow ViT, i.e., one self-attention layer followed by a two-layer\\nperceptron, for a classification task. We characterize the sample complexity to\\nachieve a zero generalization error. Our sample complexity bound is positively\\ncorrelated with the inverse of the fraction of label-relevant tokens, the token\\nnoise level, and the initial model error. We also prove that a training process\\nusing stochastic gradient descent (SGD) leads to a sparse attention map, which\\nis a formal verification of the general intuition about the success of\\nattention. Moreover, this paper indicates that a proper token sparsification\\ncan improve the test performance by removing label-irrelevant and/or noisy\\ntokens, including spurious correlations. Empirical experiments on synthetic\\ndata and CIFAR-10 dataset justify our theoretical results and generalize to\\ndeeper ViTs.\\n\",\n",
      "    \"authors\": [\n",
      "        \"Hongkang Li\",\n",
      "        \" Meng Wang\",\n",
      "        \" Sijia Liu\",\n",
      "        \" Pin-yu Chen\"\n",
      "    ],\n",
      "    \"source\": \"arxiv\"\n",
      "}\n",
      "{\n",
      "    \"id\": \"2010.08242_arxiv\",\n",
      "    \"title\": \"Unsupervised Extractive Summarization by Pre-training Hierarchical\\n  Transformers\",\n",
      "    \"type\": \"paper\",\n",
      "    \"year\": 2021,\n",
      "    \"abstract\": \"  Unsupervised extractive document summarization aims to select important\\nsentences from a document without using labeled summaries during training.\\nExisting methods are mostly graph-based with sentences as nodes and edge\\nweights measured by sentence similarities. In this work, we find that\\ntransformer attentions can be used to rank sentences for unsupervised\\nextractive summarization. Specifically, we first pre-train a hierarchical\\ntransformer model using unlabeled documents only. Then we propose a method to\\nrank sentences using sentence-level self-attentions and pre-training\\nobjectives. Experiments on CNN/DailyMail and New York Times datasets show our\\nmodel achieves state-of-the-art performance on unsupervised summarization. We\\nalso find in experiments that our model is less dependent on sentence\\npositions. When using a linear combination of our model and a recent\\nunsupervised model explicitly modeling sentence positions, we obtain even\\nbetter results.\\n\",\n",
      "    \"authors\": [\n",
      "        \"Shusheng Xu\",\n",
      "        \" Xingxing Zhang\",\n",
      "        \" Yi Wu\",\n",
      "        \" Furu Wei and Ming Zhou\"\n",
      "    ],\n",
      "    \"source\": \"arxiv\"\n",
      "}\n",
      "{\n",
      "    \"id\": \"2101.10927_arxiv\",\n",
      "    \"title\": \"Attention Can Reflect Syntactic Structure (If You Let It)\",\n",
      "    \"type\": \"paper\",\n",
      "    \"year\": 2021,\n",
      "    \"abstract\": \"  Since the popularization of the Transformer as a general-purpose feature\\nencoder for NLP, many studies have attempted to decode linguistic structure\\nfrom its novel multi-head attention mechanism. However, much of such work\\nfocused almost exclusively on English -- a language with rigid word order and a\\nlack of inflectional morphology. In this study, we present decoding experiments\\nfor multilingual BERT across 18 languages in order to test the generalizability\\nof the claim that dependency syntax is reflected in attention patterns. We show\\nthat full trees can be decoded above baseline accuracy from single attention\\nheads, and that individual relations are often tracked by the same heads across\\nlanguages. Furthermore, in an attempt to address recent debates about the\\nstatus of attention as an explanatory mechanism, we experiment with fine-tuning\\nmBERT on a supervised parsing objective while freezing different series of\\nparameters. Interestingly, in steering the objective to learn explicit\\nlinguistic structure, we find much of the same structure represented in the\\nresulting attention patterns, with interesting differences with respect to\\nwhich parameters are frozen.\\n\",\n",
      "    \"authors\": [\n",
      "        \"Vinit Ravishankar\",\n",
      "        \" Artur Kulmizev\",\n",
      "        \" Mostafa Abdou\",\n",
      "        \" Anders S{\\\\o}gaard\",\n",
      "        \"\\n  Joakim Nivre\"\n",
      "    ],\n",
      "    \"source\": \"arxiv\"\n",
      "}\n",
      "\n",
      "\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"id\": \"keyword_attention_mechanism\",\n",
      "        \"type\": \"keyword\",\n",
      "        \"name\": \"Attention Mechanism\",\n",
      "        \"description\": \"A neural network component inspired by the human visual system's attention process, used to selectively focus on parts of the input data.\",\n",
      "        \"related_papers\": [\n",
      "            \"2410.18541_arxiv\",\n",
      "            \"2204.13154_arxiv\",\n",
      "            \"1810.12427_arxiv\",\n",
      "            \"2203.14263_arxiv\",\n",
      "            \"1902.02181_arxiv\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"keyword_transformer\",\n",
      "        \"type\": \"keyword\",\n",
      "        \"name\": \"Transformer\",\n",
      "        \"description\": \"A type of neural network architecture that relies heavily on attention mechanisms, often used in NLP and increasingly in computer vision.\",\n",
      "        \"related_papers\": [\n",
      "            \"2410.18541_arxiv\",\n",
      "            \"2305.07239_arxiv\",\n",
      "            \"2302.07253_arxiv\",\n",
      "            \"2010.08242_arxiv\",\n",
      "            \"2101.10927_arxiv\",\n",
      "            \"2302.06015_arxiv\"\n",
      "\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"keyword_nlp\",\n",
      "        \"type\": \"keyword\",\n",
      "        \"name\": \"Natural Language Processing (NLP)\",\n",
      "        \"description\": \"The field of computer science concerned with enabling computers to understand, interpret, and generate human language.\",\n",
      "        \"related_papers\": [\n",
      "            \"2410.18541_arxiv\",\n",
      "            \"2204.13154_arxiv\",\n",
      "            \"1810.12427_arxiv\",\n",
      "            \"1902.02181_arxiv\",\n",
      "            \"2010.08242_arxiv\",\n",
      "            \"2101.10927_arxiv\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"keyword_image_inpainting\",\n",
      "        \"type\": \"keyword\",\n",
      "        \"name\": \"Image Inpainting\",\n",
      "        \"description\": \"The task of filling in missing or corrupted parts of an image in a visually plausible way.\",\n",
      "        \"related_papers\": [\n",
      "            \"2305.07239_arxiv\"\n",
      "        ]\n",
      "    },\n",
      "        {\n",
      "        \"id\": \"keyword_summarization\",\n",
      "        \"type\": \"keyword\",\n",
      "        \"name\": \"Summarization\",\n",
      "        \"description\": \"The task of condensing a longer text into a shorter version while preserving the most important information.\",\n",
      "        \"related_papers\": [\n",
      "            \"2010.08242_arxiv\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"2410.18541_arxiv\",\n",
      "        \"title\": \"On Explaining with Attention Matrices\",\n",
      "        \"type\": \"paper\",\n",
      "        \"year\": 2024,\n",
      "        \"abstract\": \"This paper explores the explanatory link between attention weights and predicted output in transformer models. It challenges prior research that argues against the explanatory relevance of attention weights. The paper introduces \\\"efficient attention,\\\" which isolates effective components of attention matrices, demonstrating their causal role in predicting model output for NLP tasks requiring contextual information. It argues that efficient attention matrices are probability distributions and effectively calculable, thus important for explaining attention-based model behavior. Empirical experiments support the method and illustrate properties of efficient attention.\",\n",
      "        \"authors\": [\"Omar Naim\", \"Nicholas Asher\"],\n",
      "        \"source\": \"arxiv\",\n",
      "        \"keywords\": [\"Attention Mechanism\", \"Transformer\", \"NLP\"]\n",
      "    }\n",
      "]\n",
      "```\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### See the result of the chat\n",
    "\n",
    "chat.test_initial_chat(user_input=user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Detect Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_additional_data_template = \"\"\"\n",
    "{user_message}\n",
    "\n",
    "{current_graph}\n",
    "\"\"\"\n",
    "chat.set_detect_additional_data_template(detect_additional_data_template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
